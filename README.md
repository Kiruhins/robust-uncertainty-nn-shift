# robust-uncertainty-nn-shift
This project explores the robustness of neural machine translation models under data distribution shift. We propose a selective fine-tuning strategy for the MBart model, targeting only “risky” inputs — those exhibiting high uncertainty via attention entropy or unstable hidden states.
